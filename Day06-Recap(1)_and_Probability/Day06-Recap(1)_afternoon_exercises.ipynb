{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YehS8enAmDn"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1cXtXdAcwedVDbapmz1pj_hULsQrhEcff\" width=\"500\"/>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8Up_Q3Z5La"
      },
      "source": [
        "# **Recap (1)**\n",
        "\n",
        "#### **Morning contents/agenda**\n",
        "\n",
        "1. Overview of contents covered\n",
        "\n",
        "2. A design and training guide\n",
        "\n",
        "3. Key network operations\n",
        "\n",
        "4. U-Net\n",
        "\n",
        "5. Backpropagation\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Afternoon contents/agenda**\n",
        "\n",
        "1. Building a U-Net from scratch\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_kYki018eTFJ",
        "outputId": "cc973fc0-5b3e-4ebd-a5da-e6937c42ce7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycm\n",
            "  Downloading pycm-4.5-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting livelossplot\n",
            "  Downloading livelossplot-0.5.6-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting art>=1.8 (from pycm)\n",
            "  Downloading art-6.5-py3-none-any.whl.metadata (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from pycm) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from livelossplot) (3.10.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.12/dist-packages (from livelossplot) (3.7.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.12.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (25.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (6.0.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (6.5.1)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2025.11.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.17.0)\n",
            "Downloading pycm-4.5-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading livelossplot-0.5.6-py3-none-any.whl (23 kB)\n",
            "Downloading art-6.5-py3-none-any.whl (610 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.4/610.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: art, pycm, livelossplot\n",
            "Successfully installed art-6.5 livelossplot-0.5.6 pycm-4.5\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LI8sNA9feT3H",
        "outputId": "0d95d2ce-3e3c-4bf5-a305-d12c301daba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfOjp9orI4g3"
      },
      "source": [
        "## 1. Building a U-Net from scratch\n",
        "\n",
        "Today, we're going to try to build our own U-Net and apply it to the problem we saw on Day03: denoising the ChestMNIST dataset.\n",
        "\n",
        "Let's follow the steps we always follow:\n",
        "\n",
        "1. Create a `Dataset` object(s) that will contain your complete dataset (either a custom one by creating a class that inherits from Dataset or one extracted directly from torch or torchvision).\n",
        "2. Create a `Dataloader` object(s) to assemble batches from the Dataset and send them to the device. At this point, you might want to use a `StratifiedShuffleSplit` to separate between validation and training loaders.\n",
        "3. Create a model, either by using a new `nn.Module` class or by downloading a predefined network like Alexnet.\n",
        "4. Instantiate an appropriate criterion like MSE or CrossEntropy.\n",
        "5. Instantiate an optimizer like SGD or Adam.\n",
        "6. Create the train, validation, and test loops.\n",
        "7. Run over all epochs using alternatively train and validation.\n",
        "8. Run the test loop on the trained model.\n",
        "\n",
        "<br>\n",
        "\n",
        "Let's start by defining some hyperparameters for later:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "p = 0.6\n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "num_workers = 0\n",
        "wd = 1e-6\n",
        "nepochs = 5"
      ],
      "metadata": {
        "id": "iVSRqkFY6r4X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1. Create `Dataset` object(s)**\n",
        "\n",
        "We can now download the dataset:"
      ],
      "metadata": {
        "id": "9Ru-2WzN-mtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/record/6496656/files/chestmnist.npz"
      ],
      "metadata": {
        "id": "fEndjQIw4QSJ",
        "outputId": "ccda1a29-08cd-4d6b-a299-15f89758b65b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-01 14:35:04--  https://zenodo.org/record/6496656/files/chestmnist.npz\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.75, 188.185.43.153, 137.138.52.235, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/6496656/files/chestmnist.npz [following]\n",
            "--2025-12-01 14:35:07--  https://zenodo.org/records/6496656/files/chestmnist.npz\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82802576 (79M) [application/octet-stream]\n",
            "Saving to: ‘chestmnist.npz’\n",
            "\n",
            "chestmnist.npz      100%[===================>]  78.97M  1.47MB/s    in 48s     \n",
            "\n",
            "2025-12-01 14:36:05 (1.64 MB/s) - ‘chestmnist.npz’ saved [82802576/82802576]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"./chestmnist.npz\")"
      ],
      "metadata": {
        "id": "9N41K7LO4Rxt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And create a custom `Dataset` to take care of adding noise to the images:"
      ],
      "metadata": {
        "id": "3xo_SSLaA4an"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Tu7NRcR4YqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02NghAiN4awM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2. Create a `Dataloader` object(s)**"
      ],
      "metadata": {
        "id": "vW0c0nYO-tPW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4h0KGLg-vGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test the `Dataset` and `DataLoader`:"
      ],
      "metadata": {
        "id": "trIxHyVeA8wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gny9uAfP5rNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3. Create a model**"
      ],
      "metadata": {
        "id": "wlFPAjqn-0sN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jnnTMmfH40AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WaNupqp45gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4. Instantiate an appropriate criterion like MSE or CrossEntropy**"
      ],
      "metadata": {
        "id": "bn5o7LEO-6zu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2VH_pLa49Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.5. Instantiate an optimizer**"
      ],
      "metadata": {
        "id": "m8pdh8H3_Asj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBbwukRM_D1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.6. Create the train, validation, and test loops**"
      ],
      "metadata": {
        "id": "pM0k5QwM_JFk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHe5ruF94e4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.7. Run over all epochs**"
      ],
      "metadata": {
        "id": "BT7iX0TT_RIe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vVDl-QC4hHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to save and then reload our model:"
      ],
      "metadata": {
        "id": "TaT4oiZE_JAc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJrxv5So_Khb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iXyuOTtD_KqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.8. Run the test loop**"
      ],
      "metadata": {
        "id": "z93ogzv2_PW_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y55-SLJL4kSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPwiYNj8AfuW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}